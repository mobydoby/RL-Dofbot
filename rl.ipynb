{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41578bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e40509c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mArm_Lib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Arm_Device\n\u001b[0;32m----> 2\u001b[0m Arm \u001b[38;5;241m=\u001b[39m \u001b[43mArm_Device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Get DOFBOT object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/Arm_Lib/Arm_Lib.py:11\u001b[0m, in \u001b[0;36mArm_Device.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maddr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x15\u001b[39m\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbus \u001b[38;5;241m=\u001b[39m \u001b[43msmbus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSMBus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "from Arm_Lib import Arm_Device\n",
    "Arm = Arm_Device()  # Get DOFBOT object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c661444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7fd31d936320>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d942c5a",
   "metadata": {},
   "source": [
    "Defines Arm related functions for moving the arm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7236b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_angles(arm, angles, sec_per_angle):\n",
    "    \"\"\"Sets all the angles of arm\n",
    "    Args:\n",
    "        arm - the real robot\n",
    "        angles - the angles to set\n",
    "        t - the amount of time to move each angle\n",
    "    \"\"\"\n",
    "    t = angles*np.pi/180*sec_per_angle\n",
    "    for joint, (angle, movetime) in enumerate(zip(angles, t)):\n",
    "        arm.Arm_serial_servo_write(joint+1, angle, movetime)\n",
    "        \n",
    "def read_all_joints(arm):\n",
    "    q = np.array([arm.Arm_serial_servo_read(id) for id in range(1,6)])\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1395b496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda (device)\n"
     ]
    }
   ],
   "source": [
    "# search for gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using {device} (device)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e12dd",
   "metadata": {},
   "source": [
    "Define the architechure for the Actor and Critic Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f440823",
   "metadata": {},
   "source": [
    "Initialize Dofbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329eb128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.     0.     0.1045] [0. 0. 0.] [0.08285 0.      0.     ] [-0.      -0.      -0.08285] [0. 0. 0.] [-0.12842 -0.      -0.     ]\n",
      "[[ 0.       0.       0.08285 -0.       0.      -0.12842]\n",
      " [ 0.       0.       0.      -0.       0.      -0.     ]\n",
      " [ 0.1045   0.       0.      -0.08285  0.      -0.     ]] [[ 0  0  0  0 -1]\n",
      " [ 0 -1 -1 -1  0]\n",
      " [ 1  0  0  0  0]]\n",
      "[[  0 180]\n",
      " [  0 180]\n",
      " [  0 180]\n",
      " [  0 180]\n",
      " [  0 270]\n",
      " [  0 180]]\n"
     ]
    }
   ],
   "source": [
    "ex = np.array([1,0,0])\n",
    "ey = np.array([0,1,0])\n",
    "ez = np.array([0,0,1])\n",
    "l0 = 0.061 # base to servo 1\n",
    "l1 = 0.0435 # servo 1 to servo 2\n",
    "l2 = 0.08285 # servo 2 to servo 3\n",
    "l3 = 0.08285 # servo 3 to servo 4\n",
    "l4 = 0.07385 # servo 4 to servo 5\n",
    "l5 = 0.05457 # servo 5 to gripper\n",
    "P01 = ( l0 + l1 ) * ez \n",
    "P12 = np.zeros (3) # translation between 1 and 2 frame in 1 frame\n",
    "P23 = l2 * ex # translation between 2 and 3 frame in 2 frame\n",
    "P34 = - l3 * ez # translation between 3 and 4 frame in 3 frame\n",
    "P45 = np.zeros (3) # translation between 4 and 5 frame in 4 frame\n",
    "P5T = -( l4 + l5 ) * ex \n",
    "print(P01,P12,P23,P34,P45,P5T)\n",
    "\n",
    "P = np.array([P01, P12, P23, P34, P45, P5T]).T\n",
    "H = np.array([ez, -ey, -ey, -ey, -ex]).T\n",
    "print(P,H)\n",
    "limits = np.array([0,180] * 6).reshape(6, 2)\n",
    "limits[4, :] = [0, 270]\n",
    "print(limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43c14eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Robot import UR5Arm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2afe1a4",
   "metadata": {},
   "source": [
    "During the Training Cycle, the following steps are performed for each epoch:\n",
    "1. Initialize the Robot to a random state.\n",
    "2. select a random end effector position and orientation that\n",
    "   converges to valid joint angles using inverse kinematics\n",
    "3. Run the following in each training epoch that lasts 10 seconds per iteration\n",
    "4. The robot can takes 1 action in a discrete action space for each joint:\n",
    "   - the DQN network outputs a value between -10 and 10 and the arm is commanded to\n",
    "     move each servo that angle amount with velocity V\n",
    "5. Repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee57825-7533-4f12-b528-7fddd400cb3a",
   "metadata": {},
   "source": [
    "First we need to establish the bounds for this robot. \n",
    "We move the robot to the home position and measure the maximal length the end effector can reach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff5be62-b5ed-4f5e-b19d-2748800391fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_P_from_limits(limits, y_bound = 0.05):\n",
    "    \"\"\"Tests the target EE configuration process\n",
    "    Generates a random end effector point based on Position vector limits\n",
    "    Args:\n",
    "        limits is a tuple of the smallest and largest norms of P_ees generated\n",
    "    \"\"\"\n",
    "    match = False\n",
    "    tries = 0\n",
    "    while not match and tries<100:\n",
    "        target_norm = np.random.uniform(limits[0], limits[1])\n",
    "        print(f\"Generated Target Norm: {target_norm:.4f}\")\n",
    "        random = np.random.rand(3)\n",
    "        norm_vec = np.linalg.norm(random)\n",
    "        out = random * target_norm/norm_vec\n",
    "        if out[1] > y_bound:\n",
    "            print(\"Retrying: y value not within bounds\")\n",
    "            return out \n",
    "        tries += 1\n",
    "    print(\"No match was found, maybe the y_bound was too strict?\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941b109d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural networks\n",
    "\"\"\"\n",
    "The neural network learns an approximation of the value function\n",
    "with a neural network\n",
    "\"\"\"\n",
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636af3ac-0f4a-4be1-b68e-831416ace22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ee4046-1003-4888-8d61-a6b327bce7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "def linearity(P_start, P_end, P_curr):\n",
    "    \"\"\"returns the linearity score \n",
    "    (| P12 x P01 |) / |P12|\n",
    "    \"\"\"\n",
    "    P12 = P_end - P_start\n",
    "    P01 = P_start - P_curr\n",
    "    d = norm(np.cross(P12, P01))/norm(P12)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3404deb-fd1b-4426-8285-3efc457594b2",
   "metadata": {},
   "source": [
    "### Press the Third Button the DOFBOT\n",
    "(Set the robot to the home position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8e5ce-235e-4d2a-815d-0ac9d01d4b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = read_all_joints(Arm)[None].T * np.pi /180\n",
    "R_home, P_home = fwdkin(dofbot, j)\n",
    "limits = 0.07, P[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b37284-15b0-48c9-9aa3-e68daea1638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_arm = UR5Arm(P, H, limits)\n",
    "real_arm = Arm_Device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585a5b2-b334-4b57-9fe5-6b37d303f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(episodes: int, virtual_arm: UR5Arm, real_arm: Arm, limits):\n",
    "\n",
    "ms_per_angle = 6\n",
    "# coefficient for time weight\n",
    "ee_distance_limits = ()\n",
    "end_effector_distance_tolerance = 1e-4\n",
    "y_bound = 0.5\n",
    "t_coeff = 0.1\n",
    "conv_coef = 0.9\n",
    "l_coeff = 0.1  # weight of linearity score\n",
    "time_per_trial = 10  # in seconds\n",
    "\n",
    "BATCH_SIZE = 128  # BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "GAMMA = 0.99      # GAMMA is the discount factor as mentioned in the previous section\n",
    "EPS_START = 0.9   # EPS_START is the starting value of epsilon\n",
    "EPS_END = 0.05    # EPS_END is the final value of epsilon\n",
    "EPS_DECAY = 1000  # EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
    "TAU = 0.005       # TAU is the update rate of the target network\n",
    "LR = 1e-4         # LR is the learning rate of the ``AdamW`` optimizer\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 5\n",
    "# Get the number of state observations\n",
    "n_observations = 3\n",
    "\n",
    "policy_net = PPO(n_observations, n_actions).to(device)\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d5662-0c39-4dd6-a0af-9a9c01afbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import MultivariateNormal\n",
    "\n",
    "def optimize_model(policy_net, states, actions, old_probs, advantages, epsilon_clip=0.2):\n",
    "    # Convert lists to PyTorch tensors\n",
    "    states = torch.tensor(states, dtype=torch.float32).to(device)\n",
    "    actions = torch.tensor(actions, dtype=torch.float32).to(device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float32).to(device)\n",
    "    advantages = torch.tensor(advantages, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get current policy distribution\n",
    "    policy, _ = policy_net(states)\n",
    "    probs = policy.pdf(actions)\n",
    "\n",
    "    # Calculate ratio and surrogate loss\n",
    "    ratio = probs / old_probs\n",
    "    unclipped_loss = ratio * advantages\n",
    "    clipped_loss = torch.clamp(ratio, 1.0 - epsilon_clip, 1.0 + epsilon_clip) * advantages\n",
    "    surrogate_loss = -torch.min(unclipped_loss, clipped_loss).mean()\n",
    "\n",
    "    # Update the policy network\n",
    "    optimizer.zero_grad()\n",
    "    surrogate_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043d64e-e18d-4f8e-8479-f3486bb447bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input(curr_angles, R_curr, P_curr, target_end_effector_pose):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d28832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set gripper to position 0\n",
    "real_arm.Arm_serial_servo_write(6, 10, 500)\n",
    "# optimization and ML constants\n",
    "for ep in episodes:\n",
    "    \"\"\" generate start and end positions \"\"\"\n",
    "    P_start = generate_P_from_limits(limits, y_bound)\n",
    "    P_end = generate_P_from_limits(limits, y_bound)\n",
    "    \n",
    "    # initialize the arm to a random state. \n",
    "    set_angles(real_arm, start_P, ms_per_angle)\n",
    "    \n",
    "    # allow the arm to move for 5 seconds\n",
    "    time_start = time.time()\n",
    "    current_time = 0\n",
    "    reward = 0\n",
    "\n",
    "    curr_angles = read_all_joints()\n",
    "    R_curr, P_curr = fwdkin(dofbot, curr_angles)\n",
    "    while(current_time - time_start < time_per_trial):\n",
    "        start_time_step = time.time()\n",
    "\n",
    "        observations = create_input(curr_angles, R_curr, P_curr, target_end_effector_pose)\n",
    "        dq = policy_net(observations).T\n",
    "\n",
    "        next_angles = curr_angles + dq\n",
    "        dofbot_limits = virtual_arm.get_limits()\n",
    "        if next_angles.any() > dofbot_limits[:,0]:\n",
    "            next_angles = max(dofbot_limits[:,0], next_angles)\n",
    "            reward -= 10\n",
    "            \n",
    "        if next_angles.any() < dofbot_limits[:,1]:\n",
    "            next_angles = min(dofbot_limits[:,1], next_angles)\n",
    "            reward -= 10\n",
    "            \n",
    "        for joint_num in range(dq)\n",
    "        set_angles(real_arm, next_angles, dq * ms_per_angle)\n",
    "\n",
    "        next_angles = read_all_joints()\n",
    "        R_next, P_next = fwdkin(dofbot, curr_angles)\n",
    "        \n",
    "        current_time = time.time()\n",
    "        elapsed_time = current_time - start_time_step\n",
    "        \n",
    "        dist = np.linalg.norm(P_end - P_curr) \n",
    "        lin_score = linearity(P_start, P_end, P_curr)\n",
    "        # loss should be based on the euclidean distance, time it took, and linearity of the path\n",
    "        reward -= conv_coef * dist - tcoef * elapsed_time - l_coef * lin_score\n",
    "\n",
    "        \"\"\"\n",
    "        TODO: add replay Memory for stability\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        \n",
    "        TODO: add replayMemory for stability\n",
    "        optimize_model_batch\n",
    "        \"\"\"\n",
    "        \n",
    "        if dist.all() < end_effector_distance_tolerance:\n",
    "            break\n",
    "\n",
    "        # PPO update without replay buffer\n",
    "        \"\"\" \n",
    "        To-do \n",
    "        check this and see what this is doing\n",
    "        \"\"\"\n",
    "        optimize_model(policy_net, observations, dq, old_probs, advantages)\n",
    "        \n",
    "        current_time = time.time()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062d11d-9e92-4bb7-96b9-0ec3fbd0fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
